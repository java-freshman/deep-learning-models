{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clothing retrieval based on images\n",
    "\n",
    "## 1. procedure for similar clothing retrieval\n",
    "- use the YOLO-V3 model to crop the target clothing from original images;\n",
    "- use the MobileNet model to extract the representative features (1024 dims) of the target clothing;\n",
    "- apply the cosine similarity to retrieve the similar clothing.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/similar retrieval diagram.jpg\" height=\"400\" width=\"500\">\n",
    "<p> <em> Figure 1. Diagram of the clothing retrieval procedure </em> </p>\n",
    "</div>\n",
    "\n",
    "## 2. object detection\n",
    "- new label 1324 clothing images: <em>image statistics: {'shoes': 466, 't_shirt': 198, 'skirt': 145, 'glove': 43, 'blouse': 74, 'sweater': 195, 'pants': 176, 'coat': 134, 'dress': 159, 'polo_shirt': 200, 'hat': 246, 'shirt': 164}</em>;\n",
    "\n",
    "- fine tuning of the YOLO-V3 model: <em>according to [keras-yolo3](https://github.com/qqwweee/keras-yolo3)</em>;\n",
    "\n",
    "- results analysis.\n",
    "  * crawl top 10 best sale categories of the GS clothing (in total 641,262 pics);\n",
    "  * trained YOLO-V3 model performance: \n",
    "  the label ACC is not good, however we care more about \n",
    "  the bndbox because what we need in current project is \n",
    "  to crop the target objects out of the original images \n",
    "  correctly. From the following table we can see that \n",
    "  the bndbox ACC is high for all available categories \n",
    "  except the dress category. After carefully analysis, \n",
    "  this is mostly due to confusion between the skirt and \n",
    "  dress. <em> (Note that if the model mistakes between \n",
    "  the skirt and polo-shir (or blouse), we still consider\n",
    "  the bndbox is correct because of both of them locate at\n",
    "  the same position of the body. But the dress category\n",
    "  is the one we need to improve next.)</em>\n",
    "  \n",
    "| category | image number | label ACC | bndbox ACC |\n",
    "| :-------:  | :-------: | :-------: | :-------: |\n",
    "| t-shirt  | 205660 | 64.6% | 97.1% |\n",
    "| pants | 142929 | 76.9% | 93.1% |\n",
    "| bra/panty set | 16527 | NA | NA |\n",
    "| blouse | 44195 | 26.7% | 98.4% |\n",
    "| dress | 72586 | 49.56% | 49.56% |\n",
    "| panties | 30178 | NA | NA |\n",
    "| socks | 16851 | NA | NA |\n",
    "| swimsuit | 54659 | NA | NA |\n",
    "| shirt | 41698 | 90.7% | 97.1% |\n",
    "| cardigan | 15979 | 21.7% | 96.% |\n",
    "\n",
    "\n",
    "## 3. Retrieval Results: whole image retrieval VS object proposal retrieval\n",
    "- whole image retrieval:\n",
    "  * results are only good when the images are simple\n",
    "- object proposal retrieval:\n",
    "  * eliminate the influence from the background (eg. Figure 1, 2, 3, 5, 7 and 8);\n",
    "  * YOLO-V3 crop process causes minor noise (eg. Figure 8, 9 and 12: shoes are detected for the images in which shoes are not the target objects; Figure 11: pants are detected for the image where sweater is the target object);\n",
    "  * YOLO-V3 model does not distinct female/male clothing (eg. Figure 6, 7, 10).\n",
    "\n",
    "<center class=\"half\">\n",
    "<img src=\"img/12663756.jpg\" width=\"50%\" align=left />\n",
    "<img src=\"img/12663756_sweater.jpg\" width=\"50%\" align=right/>\n",
    "</center>\n",
    "<p> <em> Figure 1. Left: whole image retrieval; Right: object proposal retrieval. (category, prdid) = (B43071701, 12663756) </em> </p>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/14042095.jpg\" width=\"50%\" align=left />\n",
    "<img src=\"img/14042095_skirt.jpg\" width=\"50%\" align=right/>\n",
    "<p> <em> Figure 2. (category, prdid) = (B43030101, 14042095) </em> </p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/14171938.jpg\" width=\"50%\" align=left />\n",
    "<img src=\"img/14171938_shirt.jpg\" width=\"50%\" align=right/>\n",
    "<p> <em> Figure 3. (category, prdid) = (B43071701, 14171938) </em> </p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/15571732.jpg\" width=\"400\" align=left />\n",
    "<img src=\"img/15571732_hat.jpg\" width=\"40%\" align=right/>\n",
    "<p> <em> Figure 4. (category, prdid) = (B43071701, 15571732) </em> </p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/21537227.jpg\" width=\"50%\" align=left>\n",
    "<img src=\"img/21537227_sweater.jpg\" width=\"50%\" align=right/>\n",
    "<p> <em> Figure 5. (category, prdid) = (B43030101, 21537227) </em> </p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/21546877.jpg\" height=\"400\" width=\"50%\" align=left />\n",
    "<img src=\"img/21546877_polo_shirt.jpg\" width=\"50%\" align=right />\n",
    "<p> <em> Figure 6. (category, prdid) = (B43071701, 21546877) </em> </p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/25755306.jpg\" width=\"50%\" align=left />\n",
    "<img src=\"img/25755306_sweater.jpg\" width=\"50%\" align=right/>\n",
    "<p> <em> Figure 7. (category, prdid) = (B43072101, 25755306) </em> </p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/25755307.jpg\" width=\"50%\" align=left />\n",
    "<img src=\"img/25755307_sweater.jpg\" width=\"50%\" align=right />\n",
    "<p> <em> Figure 8. (category, prdid) = (B43072101, 25755307) </em> </p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/26330643.jpg\" width=\"50%\" align=left />\n",
    "<img src=\"img/26330643_t_shirt.jpg\" width=\"50%\" align=right />\n",
    "<p> <em> Figure 9. (category, prdid) = (B43072101, 26330643) </em> </p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img/27187591.jpg\" width=\"50%\" align=left />\n",
    "<img src=\"img/27187591_t_shirt.jpg\" width=\"50%\" align=right />\n",
    "<p> <em> Figure 10. (category, prdid) = (B43072101, 27187591) </em> </p>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<img src=\"img/29272047.jpg\" width=\"50%\" align=left />\n",
    "<img src=\"img/29272047_pants.jpg\" width=\"50%\" align=right />\n",
    "<em> Figure 11. (category, prdid) = (B43072101, 29272047) </em>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<img src=\"img/30045407.jpg\" width=\"50%\" align=left />\n",
    "<img src=\"img/30045407_sweater.jpg\" width=\"50%\" align=right />\n",
    "<em> Figure 12. (category, prdid) = (B43072101, 30045407) </em> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
